{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from random import uniform, seed\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from igraph import *\n",
    "import random\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_RRS(G,p):   \n",
    "    \"\"\"\n",
    "    Inputs: G:  Ex2 dataframe of directed edges. Columns: ['source','target']\n",
    "            p:  Disease propagation probability\n",
    "    Return: A random reverse reachable set expressed as a list of nodes\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1. Select random source node\n",
    "    source = random.choice(np.unique(G['source']))\n",
    "    \n",
    "    # Step 2. Get an instance of g from G by sampling edges  \n",
    "    g = G.copy().loc[np.random.uniform(0,1,G.shape[0]) < G['probability'].tolist()]\n",
    "\n",
    "    # Step 3. Construct reverse reachable set of the random source node\n",
    "    new_nodes, RRS0 = [source], [source]   \n",
    "    while new_nodes:\n",
    "        \n",
    "        # Limit to edges that flow into the source node\n",
    "        temp = g.loc[g['target'].isin(new_nodes)]\n",
    "\n",
    "        # Extract the nodes flowing into the source node\n",
    "        temp = temp['source'].tolist()\n",
    "\n",
    "        # Add new set of in-neighbors to the RRS\n",
    "        RRS = list(set(RRS0 + temp))\n",
    "\n",
    "        # Find what new nodes were added\n",
    "        new_nodes = list(set(RRS) - set(RRS0))\n",
    "\n",
    "        # Reset loop variables\n",
    "        RRS0 = RRS[:]\n",
    "\n",
    "    return(RRS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ris(G,k,p=0.5,mc=1000):    \n",
    "    \"\"\"\n",
    "    Inputs: G:  Ex2 dataframe of directed edges. Columns: ['source','target']\n",
    "            k:  Size of seed set\n",
    "            p:  Disease propagation probability\n",
    "            mc: Number of RRSs to generate\n",
    "    Return: A seed set of nodes as an approximate solution to the IM problem\n",
    "    \"\"\"\n",
    "    \n",
    "    # Step 1. Generate the collection of random RRSs\n",
    "    start_time = time.time()\n",
    "    R = [get_RRS(G,p) for _ in range(mc)]\n",
    "\n",
    "    # Step 2. Choose nodes that appear most often (maximum coverage greedy algorithm)\n",
    "    SEED, timelapse = [], []\n",
    "    for _ in range(k):\n",
    "        \n",
    "        # Find node that occurs most often in R and add to seed set\n",
    "        flat_list = [item for sublist in R for item in sublist]\n",
    "        seed = Counter(flat_list).most_common()[0][0]\n",
    "        SEED.append(seed)\n",
    "        \n",
    "        # Remove RRSs containing last chosen seed \n",
    "        R = [rrs for rrs in R if seed not in rrs]\n",
    "        \n",
    "        # Record Time\n",
    "        timelapse.append(time.time() - start_time)\n",
    "    \n",
    "    return(sorted(SEED),timelapse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "import pickle\n",
    "import argparse\n",
    "\n",
    "from utils_isf import *\n",
    "\n",
    "parser = argparse.ArgumentParser(description=\"ISF algorithm\")\n",
    "datasets = ['Data', 'facebook-twitter']\n",
    "parser.add_argument(\"-d\", \"--dataset\", default=\"Data\", type=str,\n",
    "                    help=\"one of: {}\".format(\", \".join(sorted(datasets))))\n",
    "num_node = [600, 5000]\n",
    "parser.add_argument(\"-nn\", \"--num_node\", default=600, type=int,\n",
    "                    help=\"one of: {}\".format(\", \".join(str(sorted(num_node)))))\n",
    "num_layer = [3, 4, 5, 6, 7, 8, 9]\n",
    "parser.add_argument(\"-nl\", \"--num_layer\", default=3, type=int,\n",
    "                    help=\"one of: {}\".format(\", \".join(str(sorted(num_layer)))))\n",
    "overlaping_user = [30, 50, 70]\n",
    "parser.add_argument(\"-ou\", \"--overlaping_user\", default=30, type=int,\n",
    "                    help=\"one of: {}\".format(\", \".join(str(sorted(overlaping_user)))))\n",
    "budgets = [10, 20, 30]\n",
    "parser.add_argument(\"-b\", \"--budget\", default=30, type=int,\n",
    "                    help=\"one of: {}\".format(\", \".join(str(sorted(budgets)))))\n",
    "\n",
    "parser.add_argument(\"-m\", \"--mc\", default=30, type=int,\n",
    "                    help=\"the number of Monte-Carlo simulations\")\n",
    "args = parser.parse_args(args=[])\n",
    "\n",
    "# Read input graph file\n",
    "file_path = '../Dataset/' + args.dataset + '/graph_' + str(args.num_node) + '_node_' + str(args.num_layer) + \\\n",
    "            '_layer_' + str(args.overlaping_user) + '_overlaping_user.pickle'\n",
    "\n",
    "file_name = os.path.splitext(os.path.basename(file_path))[0]\n",
    "with open(file_path, 'rb') as file:\n",
    "    data = pickle.load(file)\n",
    "graphs = data[0]\n",
    "combined_graph = data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df(G):\n",
    "    source_nodes = []\n",
    "    target_nodes = []\n",
    "    probs = []\n",
    "\n",
    "    for edges in G.edges():\n",
    "        p = 1 - G.get_edge_data(edges[0], edges[1])['weight']\n",
    "        if combined_graph.is_directed() == False:\n",
    "            source_nodes.extend([edges[0], edges[1]]) \n",
    "            target_nodes.extend([edges[1], edges[0]]) \n",
    "            probs.extend([p, p])\n",
    "        else:\n",
    "            source_nodes.append(edges[0])\n",
    "            target_nodes.append(edges[1])\n",
    "            probs.append(p)\n",
    "\n",
    "    df = pd.DataFrame({'source': source_nodes,'target': target_nodes, 'probability': probs})\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run algorithms\n",
    "ris_output  = ris(df,5,p=0.5,mc=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0, 164, 369, 371, 396],\n",
       " [1.3709588050842285,\n",
       "  1.3718786239624023,\n",
       "  1.3718819618225098,\n",
       "  1.3718841075897217,\n",
       "  1.3718857765197754])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ris_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 600/600 [00:05<00:00, 116.19it/s]\n",
      "100%|██████████| 4/4 [00:30<00:00,  7.51s/it]\n"
     ]
    }
   ],
   "source": [
    "S, SPREAD, timelapse, LOOKUPS, data = celf(combined_graph, k=5, mc=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([117, 75, 30, 530, 485],\n",
       " [17.49, 28.41, 41.05, 52.15, 57.53],\n",
       " [5.165317058563232,\n",
       "  7.671156644821167,\n",
       "  7.844915866851807,\n",
       "  13.397634029388428,\n",
       "  35.19011092185974])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "S, SPREAD, timelapse,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37.89,\n",
       " array([[2, 0, 0, ..., 0, 0, 0],\n",
       "        [2, 0, 0, ..., 0, 0, 0],\n",
       "        [2, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [2, 0, 0, ..., 0, 0, 0],\n",
       "        [2, 0, 0, ..., 0, 0, 0],\n",
       "        [2, 0, 0, ..., 0, 0, 0]]),\n",
       " [])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IC(combined_graph, [0, 164, 369, 371, 396], mc=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphs = sorted(graphs, key=lambda graph: (graph.number_of_nodes(), graph.number_of_edges()))\n",
    "start_time = time.time()\n",
    "\n",
    "df = get_df(combined_graph)\n",
    "S, timelapse  = ris(df,5,p=0.5,mc=1000)\n",
    "SPREAD, _, _ = IC(combined_graph, S, mc=100)\n",
    "\n",
    "save_time = time.time() - start_time\n",
    "print(\"Time\", save_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'numpy' has no attribute 'float8'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m])\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Chuyển đổi mảng về kiểu dữ liệu float8\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m array_float8 \u001b[38;5;241m=\u001b[39m array\u001b[38;5;241m.\u001b[39mastype(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat8\u001b[49m)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(array_float8)\n",
      "File \u001b[0;32m~/anaconda3/envs/DeepHyper/lib/python3.8/site-packages/numpy/__init__.py:320\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtesting\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Tester\n\u001b[1;32m    318\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Tester\n\u001b[0;32m--> 320\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    321\u001b[0m                      \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{!r}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;18m__name__\u001b[39m, attr))\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'numpy' has no attribute 'float8'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Mảng ban đầu\n",
    "array = np.array([1, 2, 3, 4, 5])\n",
    "\n",
    "# Chuyển đổi mảng về kiểu dữ liệu float8\n",
    "array_float8 = array.astype(np.float8)\n",
    "\n",
    "print(array_float8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Graph' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnetworkx\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnx\u001b[39;00m\n\u001b[1;32m      3\u001b[0m G \u001b[38;5;241m=\u001b[39m nx\u001b[38;5;241m.\u001b[39mGraph([(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)])\n\u001b[0;32m----> 4\u001b[0m A \u001b[38;5;241m=\u001b[39m \u001b[43mnx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_scipy_sparse_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mG\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/DeepHyper/lib/python3.8/site-packages/networkx/convert_matrix.py:1035\u001b[0m, in \u001b[0;36mfrom_scipy_sparse_matrix\u001b[0;34m(A, parallel_edges, create_using, edge_attribute)\u001b[0m\n\u001b[1;32m   1002\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_numpy_array\u001b[39m(A, parallel_edges\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, create_using\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m   1003\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns a graph from a 2D NumPy array.\u001b[39;00m\n\u001b[1;32m   1004\u001b[0m \n\u001b[1;32m   1005\u001b[0m \u001b[38;5;124;03m    The 2D NumPy array is interpreted as an adjacency matrix for the graph.\u001b[39;00m\n\u001b[1;32m   1006\u001b[0m \n\u001b[1;32m   1007\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[1;32m   1008\u001b[0m \u001b[38;5;124;03m    ----------\u001b[39;00m\n\u001b[1;32m   1009\u001b[0m \u001b[38;5;124;03m    A : a 2D numpy.ndarray\u001b[39;00m\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;124;03m        An adjacency matrix representation of a graph\u001b[39;00m\n\u001b[1;32m   1011\u001b[0m \n\u001b[1;32m   1012\u001b[0m \u001b[38;5;124;03m    parallel_edges : Boolean\u001b[39;00m\n\u001b[1;32m   1013\u001b[0m \u001b[38;5;124;03m        If this is True, `create_using` is a multigraph, and `A` is an\u001b[39;00m\n\u001b[1;32m   1014\u001b[0m \u001b[38;5;124;03m        integer array, then entry *(i, j)* in the array is interpreted as the\u001b[39;00m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;124;03m        number of parallel edges joining vertices *i* and *j* in the graph.\u001b[39;00m\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;124;03m        If it is False, then the entries in the array are interpreted as\u001b[39;00m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;124;03m        the weight of a single edge joining the vertices.\u001b[39;00m\n\u001b[1;32m   1018\u001b[0m \n\u001b[1;32m   1019\u001b[0m \u001b[38;5;124;03m    create_using : NetworkX graph constructor, optional (default=nx.Graph)\u001b[39;00m\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;124;03m       Graph type to create. If graph instance, then cleared before populated.\u001b[39;00m\n\u001b[1;32m   1021\u001b[0m \n\u001b[1;32m   1022\u001b[0m \u001b[38;5;124;03m    Notes\u001b[39;00m\n\u001b[1;32m   1023\u001b[0m \u001b[38;5;124;03m    -----\u001b[39;00m\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;124;03m    For directed graphs, explicitly mention create_using=nx.DiGraph,\u001b[39;00m\n\u001b[1;32m   1025\u001b[0m \u001b[38;5;124;03m    and entry i,j of A corresponds to an edge from i to j.\u001b[39;00m\n\u001b[1;32m   1026\u001b[0m \n\u001b[1;32m   1027\u001b[0m \u001b[38;5;124;03m    If `create_using` is :class:`networkx.MultiGraph` or\u001b[39;00m\n\u001b[1;32m   1028\u001b[0m \u001b[38;5;124;03m    :class:`networkx.MultiDiGraph`, `parallel_edges` is True, and the\u001b[39;00m\n\u001b[1;32m   1029\u001b[0m \u001b[38;5;124;03m    entries of `A` are of type :class:`int`, then this function returns a\u001b[39;00m\n\u001b[1;32m   1030\u001b[0m \u001b[38;5;124;03m    multigraph (of the same type as `create_using`) with parallel edges.\u001b[39;00m\n\u001b[1;32m   1031\u001b[0m \n\u001b[1;32m   1032\u001b[0m \u001b[38;5;124;03m    If `create_using` indicates an undirected multigraph, then only the edges\u001b[39;00m\n\u001b[1;32m   1033\u001b[0m \u001b[38;5;124;03m    indicated by the upper triangle of the array `A` will be added to the\u001b[39;00m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;124;03m    graph.\u001b[39;00m\n\u001b[0;32m-> 1035\u001b[0m \n\u001b[1;32m   1036\u001b[0m \u001b[38;5;124;03m    If the NumPy array has a single data type for each array entry it\u001b[39;00m\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;124;03m    will be converted to an appropriate Python data type.\u001b[39;00m\n\u001b[1;32m   1038\u001b[0m \n\u001b[1;32m   1039\u001b[0m \u001b[38;5;124;03m    If the NumPy array has a user-specified compound data type the names\u001b[39;00m\n\u001b[1;32m   1040\u001b[0m \u001b[38;5;124;03m    of the data fields will be used as attribute keys in the resulting\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;124;03m    NetworkX graph.\u001b[39;00m\n\u001b[1;32m   1042\u001b[0m \n\u001b[1;32m   1043\u001b[0m \u001b[38;5;124;03m    See Also\u001b[39;00m\n\u001b[1;32m   1044\u001b[0m \u001b[38;5;124;03m    --------\u001b[39;00m\n\u001b[1;32m   1045\u001b[0m \u001b[38;5;124;03m    to_numpy_array\u001b[39;00m\n\u001b[1;32m   1046\u001b[0m \n\u001b[1;32m   1047\u001b[0m \u001b[38;5;124;03m    Examples\u001b[39;00m\n\u001b[1;32m   1048\u001b[0m \u001b[38;5;124;03m    --------\u001b[39;00m\n\u001b[1;32m   1049\u001b[0m \u001b[38;5;124;03m    Simple integer weights on edges:\u001b[39;00m\n\u001b[1;32m   1050\u001b[0m \n\u001b[1;32m   1051\u001b[0m \u001b[38;5;124;03m    >>> import numpy as np\u001b[39;00m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;124;03m    >>> A = np.array([[1, 1], [2, 1]])\u001b[39;00m\n\u001b[1;32m   1053\u001b[0m \u001b[38;5;124;03m    >>> G = nx.from_numpy_array(A)\u001b[39;00m\n\u001b[1;32m   1054\u001b[0m \u001b[38;5;124;03m    >>> G.edges(data=True)\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;124;03m    EdgeDataView([(0, 0, {'weight': 1}), (0, 1, {'weight': 2}), (1, 1, {'weight': 1})])\u001b[39;00m\n\u001b[1;32m   1056\u001b[0m \n\u001b[1;32m   1057\u001b[0m \u001b[38;5;124;03m    If `create_using` indicates a multigraph and the array has only integer\u001b[39;00m\n\u001b[1;32m   1058\u001b[0m \u001b[38;5;124;03m    entries and `parallel_edges` is False, then the entries will be treated\u001b[39;00m\n\u001b[1;32m   1059\u001b[0m \u001b[38;5;124;03m    as weights for edges joining the nodes (without creating parallel edges):\u001b[39;00m\n\u001b[1;32m   1060\u001b[0m \n\u001b[1;32m   1061\u001b[0m \u001b[38;5;124;03m    >>> A = np.array([[1, 1], [1, 2]])\u001b[39;00m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;124;03m    >>> G = nx.from_numpy_array(A, create_using=nx.MultiGraph)\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;124;03m    >>> G[1][1]\u001b[39;00m\n\u001b[1;32m   1064\u001b[0m \u001b[38;5;124;03m    AtlasView({0: {'weight': 2}})\u001b[39;00m\n\u001b[1;32m   1065\u001b[0m \n\u001b[1;32m   1066\u001b[0m \u001b[38;5;124;03m    If `create_using` indicates a multigraph and the array has only integer\u001b[39;00m\n\u001b[1;32m   1067\u001b[0m \u001b[38;5;124;03m    entries and `parallel_edges` is True, then the entries will be treated\u001b[39;00m\n\u001b[1;32m   1068\u001b[0m \u001b[38;5;124;03m    as the number of parallel edges joining those two vertices:\u001b[39;00m\n\u001b[1;32m   1069\u001b[0m \n\u001b[1;32m   1070\u001b[0m \u001b[38;5;124;03m    >>> A = np.array([[1, 1], [1, 2]])\u001b[39;00m\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;124;03m    >>> temp = nx.MultiGraph()\u001b[39;00m\n\u001b[1;32m   1072\u001b[0m \u001b[38;5;124;03m    >>> G = nx.from_numpy_array(A, parallel_edges=True, create_using=temp)\u001b[39;00m\n\u001b[1;32m   1073\u001b[0m \u001b[38;5;124;03m    >>> G[1][1]\u001b[39;00m\n\u001b[1;32m   1074\u001b[0m \u001b[38;5;124;03m    AtlasView({0: {'weight': 1}, 1: {'weight': 1}})\u001b[39;00m\n\u001b[1;32m   1075\u001b[0m \n\u001b[1;32m   1076\u001b[0m \u001b[38;5;124;03m    User defined compound data type on edges:\u001b[39;00m\n\u001b[1;32m   1077\u001b[0m \n\u001b[1;32m   1078\u001b[0m \u001b[38;5;124;03m    >>> dt = [(\"weight\", float), (\"cost\", int)]\u001b[39;00m\n\u001b[1;32m   1079\u001b[0m \u001b[38;5;124;03m    >>> A = np.array([[(1.0, 2)]], dtype=dt)\u001b[39;00m\n\u001b[1;32m   1080\u001b[0m \u001b[38;5;124;03m    >>> G = nx.from_numpy_array(A)\u001b[39;00m\n\u001b[1;32m   1081\u001b[0m \u001b[38;5;124;03m    >>> G.edges()\u001b[39;00m\n\u001b[1;32m   1082\u001b[0m \u001b[38;5;124;03m    EdgeView([(0, 0)])\u001b[39;00m\n\u001b[1;32m   1083\u001b[0m \u001b[38;5;124;03m    >>> G[0][0][\"cost\"]\u001b[39;00m\n\u001b[1;32m   1084\u001b[0m \u001b[38;5;124;03m    2\u001b[39;00m\n\u001b[1;32m   1085\u001b[0m \u001b[38;5;124;03m    >>> G[0][0][\"weight\"]\u001b[39;00m\n\u001b[1;32m   1086\u001b[0m \u001b[38;5;124;03m    1.0\u001b[39;00m\n\u001b[1;32m   1087\u001b[0m \n\u001b[1;32m   1088\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   1089\u001b[0m     kind_to_python_type \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   1090\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mfloat\u001b[39m,\n\u001b[1;32m   1091\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mi\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1097\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mV\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvoid\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1098\u001b[0m     }\n\u001b[1;32m   1099\u001b[0m     G \u001b[38;5;241m=\u001b[39m nx\u001b[38;5;241m.\u001b[39mempty_graph(\u001b[38;5;241m0\u001b[39m, create_using)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Graph' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "import networkx as nx\n",
    "\n",
    "G = nx.Graph([(1, 1)])\n",
    "A = nx.from_scipy_sparse_matrix(G)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepHyper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
